{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87a9bad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\hp\\miniconda3\\lib\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from opencv-python) (1.23.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6690916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import load_model\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba2e3cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "445e3743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelP(imgArea):\n",
    "    \n",
    "    data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "    image = Image.open(imgArea)\n",
    "    size = (224, 224)\n",
    "    image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
    "    image_array = np.asarray(image)\n",
    "    normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "    data[0] = normalized_image_array\n",
    "    prediction = model.predict(data)\n",
    "    class_name=['male','female']\n",
    "    txt=class_name[np.argmax(prediction)] + '==> male:' + str(prediction[0][0]*100) + ' female: ' + str(prediction[0][1]*100)\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d96a3ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_11624\\2590451061.py:6: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  image = ImageOps.fit(image, size, Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "['female==> male:11.038060486316681 female: 88.96193504333496', 'female==> male:22.380810976028442 female: 77.61918306350708', 'male==> male:79.49475646018982 female: 20.50524204969406', 'male==> male:82.01141357421875 female: 17.988581955432892', 'male==> male:78.64617705345154 female: 21.353821456432343', 'male==> male:81.62813782691956 female: 18.371857702732086', 'female==> male:7.153774797916412 female: 92.84622073173523', 'male==> male:55.4760217666626 female: 44.52398121356964', 'female==> male:24.966873228549957 female: 75.03312230110168']\n"
     ]
    }
   ],
   "source": [
    "aaa=[]\n",
    "\n",
    "\n",
    "#haarcascades 불러오기\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "\n",
    "#이미지 불러오기\n",
    "img = cv2.imread('two.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "#얼굴 찾기\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "\n",
    "#font\n",
    "blue = (255, 0, 0)\n",
    "green= (0, 255, 0)\n",
    "red= (0, 0, 255)\n",
    "white= (255, 255, 255)\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "#count\n",
    "result = 0 \n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    \n",
    "    result += 1\n",
    "    cv2.rectangle(img, (x-20, y-20), (x + w+20, y + h+20), (255, 0, 0), 2)\n",
    "    img = cv2.putText(img, str(result), (x-20, y-30), font, 1, blue, 1, cv2.LINE_AA)\n",
    "    \n",
    "    roi_color = img[y-20:y + h+20, x-20:x + w+20]\n",
    "    cv2.imwrite('face_result\\\\'+str(result)+'.jpg',roi_color)\n",
    "    pre=modelP('face_result\\\\'+str(result)+'.jpg')\n",
    "    aaa.append(pre)\n",
    "    #print(aaa)\n",
    "\n",
    "    \n",
    "print(aaa)\n",
    "cv2.imshow('image', img)\n",
    "key = cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "164272e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total count => male:5 female:4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gubun=[i.split('==>')[0] for i in aaa]\n",
    "re=np.unique(gubun, return_counts=True)\n",
    "plt.bar(re[0],re[1])\n",
    "txt='total count => male:' + str(re[1][1]) + ' female:'+str(re[1][0])\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a67936ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('two.jpg')\n",
    "# 폰트 색상 지정\n",
    "\n",
    "\n",
    "blue = (255, 0, 0)\n",
    "green= (0, 255, 0)\n",
    "red= (0, 0, 255)\n",
    "white= (255, 255, 255)\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "img = cv2.putText(img, txt, (10, 30), font, 2, blue, 1, cv2.LINE_AA)\n",
    "\n",
    "for (x, y, w, h),result in zip(faces,aaa):\n",
    "    \n",
    "    cv2.rectangle(img, (x-20, y-20), (x + w+20, y + h+20), (255, 0, 0), 2)\n",
    "    img = cv2.putText(img, result, (x, y-30), font, 1, blue, 1, cv2.LINE_AA)\n",
    "    \n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
